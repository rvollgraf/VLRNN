{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd00e80b4ef12ffa400ce9597654257a096cee90a5ef9d56db7473842fe06e05def",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from collections import namedtuple\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from utilities import BreakUp, Combine, combine_packed_sequence, struct_flatten, struct_unflatten, struct_equal\n",
    "from block_rnn import SequenceStruct, BlockRNN\n",
    "from torch.nn.utils.rnn import PackedSequence, pack_sequence, pad_packed_sequence\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Globals = namedtuple(\"globals\", \"n_batch n_x n_in n_hidden n_out n_seq dtype var\")\n",
    "globals =  Globals(\n",
    "        n_batch = 8,\n",
    "        n_x = 2,\n",
    "        n_in = 18,\n",
    "        n_hidden = 32,\n",
    "        n_out = 5,\n",
    "        n_seq = 100,\n",
    "        dtype = torch.double,\n",
    "        var = 'PACKED',\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output model\n",
    "class Outp(nn.Sequential):\n",
    "\n",
    "    def __init__(sel, n_hidden, n_out):\n",
    "        super().__init__( nn.Linear(n_hidden ,10) ,nn.ELU() ,nn.Linear(10 ,n_out))\n",
    "\n",
    "    def _forward(self, z, y):\n",
    "        logits = super().forward(z)\n",
    "        return -torch.distributions.Categorical(logits=logits).log_prob(y)\n",
    "\n",
    "    def forward(self, z, y):\n",
    "        if isinstance(z, torch.Tensor):\n",
    "            return self._forward(z,y)\n",
    "        else:\n",
    "            l = PackedSequence(data=self._forward(z.data, y.data), batch_sizes=z.batch_sizes, \n",
    "                               sorted_indices=z.sorted_indices, unsorted_indices=z.unsorted_indices)    \n",
    "            return l\n",
    "\n",
    "outp = Outp(globals.n_hidden, globals.n_out).to(globals.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rnn models\n",
    "class FancyRNN(nn.Module):\n",
    "\n",
    "    def __init__(self, n_in, n_hidden):\n",
    "        super().__init__()\n",
    "        self.gru = nn.GRU(n_in, 2* n_hidden, batch_first=True)\n",
    "        self.lstm = nn.LSTM(2 * n_hidden, n_hidden, batch_first=True, num_layers=3)\n",
    "\n",
    "    def forward(self, x, h):\n",
    "        tmp, h_gru = self.gru(x, None if h is None else h[0])\n",
    "        z, h_lstm = self.lstm(tmp, None if h is None else h[1])\n",
    "\n",
    "        return z, (h_gru, h_lstm)\n",
    "\n",
    "\n",
    "\n",
    "rnn = nn.GRU(globals.n_in, globals.n_hidden, batch_first=True).to(globals.dtype)\n",
    "#rnn = nn.LSTM(globals.n_in, globals.n_hidden, batch_first=True, num_layers=3).to(globals.dtype)\n",
    "#rnn = FancyRNN(globals.n_in, globals.n_hidden).to(globals.dtype)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(globals):\n",
    "\n",
    "    if globals.var=='FIXED':\n",
    "        lengths = torch.randint(globals.n_seq//5, globals.n_seq+1, (globals.n_batch,)) \n",
    "        x = pack_sequence([torch.randn(l, globals.n_in, dtype=globals.dtype) for l in lengths], enforce_sorted=False)\n",
    "        y = pack_sequence([torch.randint(0, globals.n_out, (l,)) for l in lengths], enforce_sorted=False)\n",
    "       \n",
    "    else:\n",
    "        x = torch.randn(globals.n_batch, globals.n_seq, globals.n_in, dtype=globals.dtype)\n",
    "        y = torch.randint(0, globals.n_out, (globals.n_batch, globals.n_seq))\n",
    "\n",
    "    return x,y    \n",
    "\n",
    "x,y = create_sequences(globals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([1.6339, 1.6191, 1.6190, 1.6700, 1.6441, 1.6817, 1.5788, 1.6251],\n       dtype=torch.float64, grad_fn=<MeanBackward1>)\nloss (standard computation) 13.071750\n"
     ]
    }
   ],
   "source": [
    "        loss_scale = 'MEAN'\n",
    "        \n",
    "        mods = nn.ModuleList([outp, rnn])\n",
    "        z, h = rnn(x, None)\n",
    "\n",
    "        l_std = outp(z, y)\n",
    "        if globals.var=='FIXED':\n",
    "            l_std, lens = pad_packed_sequence(l_std, batch_first=True) \n",
    "            l_std = l_std.sum(1)\n",
    "            if loss_scale == \"MEAN\":\n",
    "                l_std /= lens\n",
    "        else:\n",
    "            l_std = l_std.mean(1) if loss_scale == \"MEAN\" else l_std.sum(1)\n",
    "        print(l_std)\n",
    "        l_std = l_std.sum()\n",
    "\n",
    "        l_std.backward()\n",
    "        l_std = l_std.item()\n",
    "        g_std = [p.grad.clone() for p in mods.parameters()]\n",
    "        print(\"loss (standard computation) {:.6f}\".format(l_std))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "'int' object is not subscriptable",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-12e88408f7d6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mvlrnn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBlockRNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_scale\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0ml_chunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvlrnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mg_chunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmods\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"loss (chunked computation) {:.6f}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml_chunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/VLRNN/block_rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, h0, y, N)\u001b[0m\n\u001b[1;32m    337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_scaling\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"MEAN\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 339\u001b[0;31m                 \u001b[0mscale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseq_lengths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msorted_indices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mloss_n\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_seq\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    340\u001b[0m                 \u001b[0mloss_n\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_n\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseq_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# leading to (unpacked) sequences of lengths 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m                 \u001b[0mloss_n\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_n\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# now we have a scalar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'int' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "        N=7\n",
    "        \n",
    "        mods.zero_grad()\n",
    "\n",
    "        vlrnn = BlockRNN(rnn, outp, loss_scale)\n",
    "        l_chunk = vlrnn(x, None, y,  N)\n",
    "        g_chunk = [p.grad.clone() for p in mods.parameters()]\n",
    "        print(\"loss (chunked computation) {:.6f}\".format(l_chunk))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "all([torch.allclose(g1, g2) for g1, g2 in zip(g_chunk, g_std )])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([21, 68, 63, 75, 25, 48, 26, 79])"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}